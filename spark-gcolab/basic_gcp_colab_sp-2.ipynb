{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t32wpceMzoXX"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://sdk.cloud.google.com | bash"
      ],
      "metadata": {
        "id": "Me5lq5B10zwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud init"
      ],
      "metadata": {
        "id": "syl3LVMoz32f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir gcc_temp"
      ],
      "metadata": {
        "id": "8Wueokw80NuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://dhope-input-data/spark/sales.csv.txt ./gcc_temp/."
      ],
      "metadata": {
        "id": "dlrmLLY-0THy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-bigquery-storage pyarrow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sdKGCTta0rcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XyxtSjLE08xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField,IntegerType,StringType,DateType\n",
        "\n",
        "d_schema = StructType([\n",
        "    StructField(\"product_id\" ,StringType(),True),\n",
        "    StructField(\"customer_id\" ,StringType(),True),\n",
        "    StructField(\"order_date\" ,StringType(),True),\n",
        "    StructField(\"location\" ,StringType(),True),\n",
        "    StructField(\"source_order\" ,StringType(),True)\n",
        "]\n",
        ")\n",
        "\n",
        "df = spark.read\\\n",
        "    .option(\"header\", \"false\")\\\n",
        "    .format(\"csv\")\\\n",
        "    .schema(d_schema)\\\n",
        "    .load(\"./gcc_temp/sales.csv.txt\")\n",
        "\n",
        "df.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lcN5F9q21zYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas_gbq\n",
        "\n",
        "project_id = \"dwhp-437913\"\n",
        "table_id = 'db1.tb_colab_test2'\n",
        "\n",
        "dfp = df.toPandas()\n",
        "\n",
        "##if_existsstr replace / fail\n",
        "\n",
        "pandas_gbq.to_gbq(dfp , table_id, project_id=project_id ,if_exists='append')"
      ],
      "metadata": {
        "id": "0S9M9iSv-UM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = {\n",
        "   'query': {\n",
        "     \"useQueryCache\": True,\n",
        "     \"use_bqstorage_api\": True\n",
        "   }\n",
        "}\n",
        "\n",
        "sql = \"select * from db1.tb_colab_test2\"\n",
        "\n",
        "##df2 = pandas_gbq.read_gbq(sql, project_id=project_id)\n",
        "##\n",
        "df2 = pandas_gbq.read_gbq(sql, project_id=project_id,configuration=configuration)\n",
        "\n",
        "df2"
      ],
      "metadata": {
        "id": "KhRh8LIKxWSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "pid = \"dwhp-437913\"\n",
        "\n",
        "client = bigquery.Client(pid)\n",
        "\n",
        "query_str = '''\n",
        "CALL `dwhp-437913.db1.sp_truncate_test2`();\n",
        "'''\n",
        "\n",
        "print (client )\n",
        "\n",
        "query_job = client.query(query_str)\n",
        "rows = list(query_job.result())\n",
        "print(rows)\n"
      ],
      "metadata": {
        "id": "z05FcVaDyF4S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}